import os
import queue
import random
import threading
import time
import traceback
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, List, Optional, Tuple, Union

import google.generativeai as genai
from google.api_core import exceptions as google_exceptions

from common.Logger import logger
from common.config import Config
from common.translations import get_translator
from utils.file_manager import file_manager
from utils.sync_utils import sync_utils

# è·å–ç¿»è¯‘å‡½æ•°
t = get_translator().t


class PendingKey:
    """å¾…éªŒè¯å¯†é’¥ä¿¡æ¯"""
    def __init__(self, key: str, repo_name: str, file_path: str, file_url: str):
        self.key = key
        self.repo_name = repo_name
        self.file_path = file_path
        self.file_url = file_url
        self.timestamp = time.time()


class KeyValidator:
    """å¼‚æ­¥å¯†é’¥éªŒè¯ç®¡ç†å™¨"""

    def __init__(self, max_workers: int = 5):
        """
        åˆå§‹åŒ–å¯†é’¥éªŒè¯ç®¡ç†å™¨
        
        Args:
            max_workers: æœ€å¤§å¹¶å‘éªŒè¯çº¿ç¨‹æ•°
        """
        self.validation_queue = queue.Queue()
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="KeyValidator")
        self.shutdown_flag = False
        
        # éªŒè¯ç»“æœç»Ÿè®¡
        self.stats = {
            "total_queued": 0,
            "total_validated": 0,
            "valid_keys": 0,
            "rate_limited_keys": 0,
            "invalid_keys": 0,
            "paid_keys": 0
        }
        self.stats_lock = threading.Lock()
        
        # æŒ‰æ–‡ä»¶åˆ†ç»„çš„éªŒè¯ç»“æœï¼ˆç”¨äºæ‰¹é‡ä¿å­˜ï¼‰
        self.results_by_file: Dict[str, Dict[str, List[str]]] = {}
        self.results_lock = threading.Lock()
        
        # å¯åŠ¨éªŒè¯å·¥ä½œçº¿ç¨‹
        for i in range(max_workers):
            self.executor.submit(self._validation_worker, i)
        
        logger.info(f"ğŸš€ å¼‚æ­¥å¯†é’¥éªŒè¯å™¨å·²å¯åŠ¨ï¼Œå¹¶å‘æ•°: {max_workers}")

    def add_key(self, key: str, repo_name: str, file_path: str, file_url: str) -> None:
        """
        æ·»åŠ å¯†é’¥åˆ°éªŒè¯é˜Ÿåˆ—
        
        Args:
            key: APIå¯†é’¥
            repo_name: ä»“åº“åç§°
            file_path: æ–‡ä»¶è·¯å¾„
            file_url: æ–‡ä»¶URL
        """
        pending_key = PendingKey(key, repo_name, file_path, file_url)
        self.validation_queue.put(pending_key)
        
        with self.stats_lock:
            self.stats["total_queued"] += 1

    def _validate_gemini_key(self, api_key: str) -> Union[bool, str]:
        """
        éªŒè¯ Gemini API å¯†é’¥
        
        Args:
            api_key: Gemini APIå¯†é’¥
            
        Returns:
            "ok" è¡¨ç¤ºæœ‰æ•ˆï¼Œå…¶ä»–å­—ç¬¦ä¸²è¡¨ç¤ºå¤±è´¥åŸå› 
        """
        try:
            time.sleep(random.uniform(0.5, 1.5))

            # è·å–éšæœºä»£ç†é…ç½®
            proxy_config = Config.get_random_proxy()
            
            client_options = {
                "api_endpoint": "generativelanguage.googleapis.com"
            }
            
            # å¦‚æœæœ‰ä»£ç†é…ç½®ï¼Œæ·»åŠ åˆ°client_optionsä¸­
            if proxy_config:
                os.environ['grpc_proxy'] = proxy_config.get('http')

            genai.configure(
                api_key=api_key,
                client_options=client_options,
            )

            model = genai.GenerativeModel(Config.HAJIMI_CHECK_MODEL)
            response = model.generate_content("hi")
            return "ok"
        except (google_exceptions.PermissionDenied, google_exceptions.Unauthenticated) as e:
            return "not_authorized_key"
        except google_exceptions.TooManyRequests as e:
            return "rate_limited"
        except Exception as e:
            if "429" in str(e) or "rate limit" in str(e).lower() or "quota" in str(e).lower():
                return "rate_limited:429"
            elif "403" in str(e) or "SERVICE_DISABLED" in str(e) or "API has not been used" in str(e):
                return "disabled"
            else:
                return f"error:{e.__class__.__name__}"

    def _validate_paid_model_key(self, api_key: str) -> Union[bool, str]:
        """
        éªŒè¯å¯†é’¥æ˜¯å¦æ”¯æŒä»˜è´¹æ¨¡å‹
        
        Args:
            api_key: Gemini APIå¯†é’¥
            
        Returns:
            "ok" è¡¨ç¤ºä»˜è´¹æ¨¡å‹å¯ç”¨ï¼Œå…¶ä»–å­—ç¬¦ä¸²è¡¨ç¤ºéªŒè¯å¤±è´¥çš„åŸå› 
        """
        try:
            time.sleep(random.uniform(0.5, 1.5))

            # è·å–éšæœºä»£ç†é…ç½®
            proxy_config = Config.get_random_proxy()
            
            client_options = {
                "api_endpoint": "generativelanguage.googleapis.com"
            }
            
            # å¦‚æœæœ‰ä»£ç†é…ç½®ï¼Œæ·»åŠ åˆ°client_optionsä¸­
            if proxy_config:
                os.environ['grpc_proxy'] = proxy_config.get('http')

            genai.configure(
                api_key=api_key,
                client_options=client_options,
            )

            model = genai.GenerativeModel(Config.HAJIMI_PAID_MODEL)
            response = model.generate_content("hi")
            return "ok"
        except (google_exceptions.PermissionDenied, google_exceptions.Unauthenticated) as e:
            return "not_authorized_for_paid"
        except google_exceptions.TooManyRequests as e:
            return "rate_limited"
        except Exception as e:
            if "429" in str(e) or "rate limit" in str(e).lower() or "quota" in str(e).lower():
                return "rate_limited"
            elif "403" in str(e) or "SERVICE_DISABLED" in str(e) or "API has not been used" in str(e):
                return "disabled"
            elif "not found" in str(e).lower() or "404" in str(e):
                return "model_not_found"
            else:
                return f"error:{e.__class__.__name__}"

    def _validation_worker(self, worker_id: int) -> None:
        """
        éªŒè¯å·¥ä½œçº¿ç¨‹
        
        Args:
            worker_id: å·¥ä½œçº¿ç¨‹ID
        """
        logger.info(f"ğŸ”§ éªŒè¯å·¥ä½œçº¿ç¨‹ #{worker_id} å·²å¯åŠ¨")
        
        while not self.shutdown_flag:
            try:
                # ä»é˜Ÿåˆ—è·å–å¾…éªŒè¯å¯†é’¥ï¼Œè¶…æ—¶5ç§’
                try:
                    pending_key = self.validation_queue.get(timeout=5)
                except queue.Empty:
                    continue
                
                key = pending_key.key
                repo_name = pending_key.repo_name
                file_path = pending_key.file_path
                file_url = pending_key.file_url
                
                # æ‰§è¡ŒéªŒè¯
                validation_result = self._validate_gemini_key(key)
                
                # åˆå§‹åŒ–ç»“æœå­˜å‚¨
                file_key = f"{repo_name}::{file_path}"
                with self.results_lock:
                    if file_key not in self.results_by_file:
                        self.results_by_file[file_key] = {
                            "repo_name": repo_name,
                            "file_path": file_path,
                            "file_url": file_url,
                            "valid_keys": [],
                            "rate_limited_keys": [],
                            "paid_keys": []
                        }
                
                # å¤„ç†éªŒè¯ç»“æœ
                if validation_result and "ok" in validation_result:
                    # æœ‰æ•ˆå¯†é’¥
                    logger.info(t('valid_key', key))
                    
                    with self.results_lock:
                        self.results_by_file[file_key]["valid_keys"].append(key)
                    
                    with self.stats_lock:
                        self.stats["valid_keys"] += 1
                    
                    # å¯¹æœ‰æ•ˆå¯†é’¥è¿›è¡Œä»˜è´¹æ¨¡å‹éªŒè¯
                    logger.info(f"ğŸ” æ­£åœ¨éªŒè¯ä»˜è´¹æ¨¡å‹: {key[:20]}...")
                    paid_validation_result = self._validate_paid_model_key(key)
                    if paid_validation_result and "ok" in paid_validation_result:
                        logger.info(f"ğŸ’ ä»˜è´¹å¯†é’¥éªŒè¯æˆåŠŸ: {key[:20]}... (æ”¯æŒ{Config.HAJIMI_PAID_MODEL})")
                        
                        with self.results_lock:
                            self.results_by_file[file_key]["paid_keys"].append(key)
                        
                        with self.stats_lock:
                            self.stats["paid_keys"] += 1
                    else:
                        logger.info(f"â„¹ï¸ ä»˜è´¹æ¨¡å‹éªŒè¯å¤±è´¥: {key[:20]}... ({paid_validation_result})")
                
                elif "rate_limited" in validation_result:
                    # é™é€Ÿå¯†é’¥
                    logger.warning(t('rate_limited_key', key, validation_result))
                    
                    # æ ¹æ®RATE_LIMITED_HANDLINGé…ç½®å†³å®šå¦‚ä½•å¤„ç†429å¯†é’¥
                    handling = Config.RATE_LIMITED_HANDLING.strip().lower()
                    
                    if handling == "discard":
                        logger.info(f"â°âŒ 429å¯†é’¥å·²ä¸¢å¼ƒ: {key[:20]}... (RATE_LIMITED_HANDLING=discard)")
                    elif handling == "save_only":
                        with self.results_lock:
                            self.results_by_file[file_key]["rate_limited_keys"].append(key)
                        logger.info(f"â°ğŸ’¾ 429å¯†é’¥ä»…æœ¬åœ°ä¿å­˜: {key[:20]}... (RATE_LIMITED_HANDLING=save_only)")
                    elif handling == "sync":
                        with self.results_lock:
                            self.results_by_file[file_key]["rate_limited_keys"].append(key)
                            self.results_by_file[file_key]["valid_keys"].append(key)
                        logger.info(f"â°âœ… 429å¯†é’¥è§†ä¸ºæ­£å¸¸å¯†é’¥: {key[:20]}... (RATE_LIMITED_HANDLING=sync)")
                    elif handling == "sync_separate":
                        with self.results_lock:
                            self.results_by_file[file_key]["rate_limited_keys"].append(key)
                        logger.info(f"â°ğŸ”„ 429å¯†é’¥å°†åŒæ­¥åˆ°ç‹¬ç«‹åˆ†ç»„: {key[:20]}... (RATE_LIMITED_HANDLING=sync_separate)")
                    else:
                        with self.results_lock:
                            self.results_by_file[file_key]["rate_limited_keys"].append(key)
                        logger.warning(f"â° æœªçŸ¥çš„RATE_LIMITED_HANDLINGå€¼: {handling}ï¼Œä½¿ç”¨é»˜è®¤è¡Œä¸º(save_only)")
                    
                    with self.stats_lock:
                        self.stats["rate_limited_keys"] += 1
                else:
                    # æ— æ•ˆå¯†é’¥
                    logger.info(t('invalid_key', key, validation_result))
                    
                    with self.stats_lock:
                        self.stats["invalid_keys"] += 1
                
                # æ›´æ–°å·²éªŒè¯è®¡æ•°
                with self.stats_lock:
                    self.stats["total_validated"] += 1
                
                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                self.validation_queue.task_done()
                
            except Exception as e:
                logger.error(f"âŒ éªŒè¯å·¥ä½œçº¿ç¨‹ #{worker_id} å‘ç”Ÿé”™è¯¯: {e}")
                traceback.print_exc()
                try:
                    self.validation_queue.task_done()
                except:
                    pass
        
        logger.info(f"ğŸ”§ éªŒè¯å·¥ä½œçº¿ç¨‹ #{worker_id} å·²åœæ­¢")

    def flush_results(self) -> Tuple[int, int, int]:
        """
        åˆ·æ–°æ‰€æœ‰éªŒè¯ç»“æœåˆ°æ–‡ä»¶å’ŒåŒæ­¥é˜Ÿåˆ—
        
        Returns:
            tuple: (valid_keys_count, rate_limited_keys_count, paid_keys_count)
        """
        total_valid = 0
        total_rate_limited = 0
        total_paid = 0
        
        with self.results_lock:
            for file_key, results in self.results_by_file.items():
                repo_name = results["repo_name"]
                file_path = results["file_path"]
                file_url = results["file_url"]
                valid_keys = results["valid_keys"]
                rate_limited_keys = results["rate_limited_keys"]
                paid_keys = results["paid_keys"]
                
                # ä¿å­˜æœ‰æ•ˆå¯†é’¥
                if valid_keys:
                    file_manager.save_valid_keys(repo_name, file_path, file_url, valid_keys)
                    logger.info(t('saved_valid_keys', len(valid_keys)))
                    
                    # æ·»åŠ åˆ°åŒæ­¥é˜Ÿåˆ—
                    try:
                        sync_utils.add_keys_to_queue(valid_keys)
                        logger.info(t('added_to_queue', len(valid_keys)))
                    except Exception as e:
                        logger.error(t('error_adding_to_queue', e))
                    
                    total_valid += len(valid_keys)
                
                # ä¿å­˜é™é€Ÿå¯†é’¥
                if rate_limited_keys:
                    file_manager.save_rate_limited_keys(repo_name, file_path, file_url, rate_limited_keys)
                    logger.info(t('saved_rate_limited_keys', len(rate_limited_keys)))
                    
                    # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦å°†429å¯†é’¥åŒæ­¥åˆ°ç‹¬ç«‹åˆ†ç»„
                    if Config.RATE_LIMITED_HANDLING.strip().lower() == "sync_separate":
                        try:
                            sync_utils.add_rate_limited_keys_to_queue(rate_limited_keys)
                            logger.info(f"â° å·²æ·»åŠ  {len(rate_limited_keys)} ä¸ª429å¯†é’¥åˆ°ç‹¬ç«‹ä¸Šä¼ é˜Ÿåˆ—")
                        except Exception as e:
                            logger.error(f"â° æ·»åŠ 429å¯†é’¥åˆ°é˜Ÿåˆ—æ—¶å‡ºé”™: {e}")
                    
                    total_rate_limited += len(rate_limited_keys)
                
                # ä¿å­˜ä»˜è´¹å¯†é’¥
                if paid_keys:
                    file_manager.save_paid_keys(repo_name, file_path, file_url, paid_keys)
                    logger.info(f"ğŸ’ å·²ä¿å­˜ä»˜è´¹å¯†é’¥: {len(paid_keys)} ä¸ª")
                    
                    # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä¸Šä¼ ä»˜è´¹å¯†é’¥åˆ°GPT-load
                    if Config.parse_bool(Config.GPT_LOAD_PAID_SYNC_ENABLED):
                        try:
                            sync_utils.add_paid_keys_to_queue(paid_keys)
                            logger.info(f"ğŸ’ å·²æ·»åŠ  {len(paid_keys)} ä¸ªä»˜è´¹å¯†é’¥åˆ°ä¸Šä¼ é˜Ÿåˆ—")
                        except Exception as e:
                            logger.error(f"ğŸ’ æ·»åŠ ä»˜è´¹å¯†é’¥åˆ°é˜Ÿåˆ—æ—¶å‡ºé”™: {e}")
                    else:
                        logger.info(f"ğŸ’ ä»˜è´¹å¯†é’¥ä¸Šä¼ åŠŸèƒ½å·²å…³é—­ï¼Œä»…æœ¬åœ°ä¿å­˜ {len(paid_keys)} ä¸ªå¯†é’¥")
                    
                    total_paid += len(paid_keys)
            
            # æ¸…ç©ºç»“æœç¼“å­˜
            self.results_by_file.clear()
        
        return total_valid, total_rate_limited, total_paid

    def get_queue_size(self) -> int:
        """è·å–å¾…éªŒè¯é˜Ÿåˆ—å¤§å°"""
        return self.validation_queue.qsize()

    def get_stats(self) -> Dict[str, int]:
        """è·å–éªŒè¯ç»Ÿè®¡ä¿¡æ¯"""
        with self.stats_lock:
            return self.stats.copy()

    def wait_completion(self, timeout: Optional[float] = None) -> bool:
        """
        ç­‰å¾…æ‰€æœ‰å¾…éªŒè¯å¯†é’¥å®Œæˆ
        
        Args:
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºæ— é™ç­‰å¾…
            
        Returns:
            bool: Trueè¡¨ç¤ºæ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ŒFalseè¡¨ç¤ºè¶…æ—¶
        """
        queue_size = self.get_queue_size()
        if queue_size > 0:
            logger.info(f"â³ ç­‰å¾… {queue_size} ä¸ªå¯†é’¥éªŒè¯å®Œæˆ...")
        
        start_time = time.time()
        last_log_time = start_time
        
        while True:
            queue_size = self.get_queue_size()
            
            # é˜Ÿåˆ—ä¸ºç©ºï¼Œä»»åŠ¡å®Œæˆ
            if queue_size == 0:
                # å†ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿æ‰€æœ‰å·¥ä½œçº¿ç¨‹å¤„ç†å®Œæˆ
                time.sleep(1)
                if self.get_queue_size() == 0:
                    logger.info("âœ… æ‰€æœ‰å¯†é’¥éªŒè¯å®Œæˆ")
                    return True
            
            # æ£€æŸ¥è¶…æ—¶
            if timeout is not None and (time.time() - start_time) > timeout:
                logger.warning(f"âš ï¸ ç­‰å¾…éªŒè¯å®Œæˆè¶…æ—¶ï¼Œå‰©ä½™ {queue_size} ä¸ªå¯†é’¥")
                return False
            
            # æ¯10ç§’è¾“å‡ºä¸€æ¬¡è¿›åº¦
            if time.time() - last_log_time >= 10:
                stats = self.get_stats()
                logger.info(f"â³ éªŒè¯è¿›åº¦: {stats['total_validated']}/{stats['total_queued']} å·²å®Œæˆï¼Œå‰©ä½™ {queue_size} ä¸ªå¾…éªŒè¯")
                last_log_time = time.time()
            
            time.sleep(1)

    def reset_stats(self) -> None:
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        with self.stats_lock:
            self.stats = {
                "total_queued": 0,
                "total_validated": 0,
                "valid_keys": 0,
                "rate_limited_keys": 0,
                "invalid_keys": 0,
                "paid_keys": 0
            }

    def shutdown(self) -> None:
        """å…³é—­éªŒè¯å™¨"""
        logger.info("ğŸ›‘ æ­£åœ¨å…³é—­å¼‚æ­¥å¯†é’¥éªŒè¯å™¨...")
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        self.wait_completion(timeout=60)
        
        # è®¾ç½®å…³é—­æ ‡å¿—
        self.shutdown_flag = True
        
        # å…³é—­çº¿ç¨‹æ± 
        self.executor.shutdown(wait=True)
        
        # åˆ·æ–°å‰©ä½™ç»“æœ
        self.flush_results()
        
        logger.info("âœ… å¼‚æ­¥å¯†é’¥éªŒè¯å™¨å·²å…³é—­")


# åˆ›å»ºå…¨å±€å®ä¾‹ï¼ˆä»é…ç½®è¯»å–å¹¶å‘æ•°ï¼‰
key_validator = KeyValidator(max_workers=Config.KEY_VALIDATOR_MAX_WORKERS)

